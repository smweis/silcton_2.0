{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Participant (NEW) data: Analysis and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import - *participant level* Master DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../CleanedData/masterDF.csv'\n",
    "df = pd.read_csv(path, encoding = 'unicode_escape', sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 35)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['good_pointing_coding_between', 'good_pointing_coding_within',\n",
       "       'bad_pointing_coding_between', 'bad_pointing_coding_within',\n",
       "       'participant', 'Original_Study_Number', 'SBSOD', 'gender', 'WRAT',\n",
       "       'Model_Building', 'Model_Building_A', 'Model_Building_B',\n",
       "       'K_Means_Across_All', 'Model_Building_Average_Within',\n",
       "       'Education_Numeric', 'New_or_Original', 'trackpad/mouse', 'Site',\n",
       "       'Experimenter ', 'NOTES', 'Age', 'Hispanic', 'Racial_Category',\n",
       "       'Racial_Category_Text', 'Education_Level', 'Education_Level_Text',\n",
       "       'Handedness', 'First_Language', 'Age_started_speaking_English',\n",
       "       'Participant_UUID_Silcton', 'date', 'MRT', 'good_pointing_coding_total',\n",
       "       'bad_pointing_coding_total', 'Color'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis - *participant level* Master DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section can be skipped, if it is not interesting. I just tried to understand the variables of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable\n",
    "'good_pointing_coding_between', \n",
    "'good_pointing_coding_within',\n",
    "'bad_pointing_coding_between', \n",
    "'bad_pointing_coding_within',\n",
    "'participant', \n",
    "'Original_Study_Number', \n",
    "'SBSOD', \n",
    "'gender', \n",
    "'WRAT',\n",
    "'Model_Building', \n",
    "'Model_Building_A', \n",
    "'Model_Building_B',\n",
    "'K_Means_Across_All', \n",
    "'Model_Building_Average_Within',\n",
    "'Education_Numeric', \n",
    "'New_or_Original', \n",
    "'trackpad/mouse', \n",
    "'Site',\n",
    "'Experimenter ', \n",
    "'NOTES', \n",
    "'Age', \n",
    "'Hispanic', \n",
    "'Racial_Category',\n",
    "'Racial_Category_Text', \n",
    "'Education_Level', \n",
    "'Education_Level_Text',\n",
    "'Handedness', \n",
    "'First_Language', \n",
    "'Age_started_speaking_English',\n",
    "'Participant_UUID_Silcton', \n",
    "'date', \n",
    "'MRT', \n",
    "'good_pointing_coding_total',\n",
    "'bad_pointing_coding_total'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describing selected variables\n",
    "x = 'good_pointing_coding_between'\n",
    "df[x].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values of selected variables\n",
    "df[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting histograms of selected variables\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(df[x], bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biplots and correlations on NEW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us have a look at selected biplots and compute correlations on NEW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to be considered\n",
    "############################\n",
    "\n",
    "# 'good_pointing_coding_between' \n",
    "# 'good_pointing_coding_within' \n",
    "# 'bad_pointing_coding_between'  \n",
    "# 'bad_pointing_coding_within'  \n",
    "# 'bad_pointing_coding_total'  \n",
    "# 'bad_pointing_coding_total'  \n",
    "\n",
    "x='good_pointing_coding_within'\n",
    "y='bad_pointing_coding_within'  \n",
    "\n",
    "# we consider only NEW data\n",
    "df_b = df[df.New_or_Original=='New']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df_b[x], df_b[y], edgecolors=(0, 0, 0))\n",
    "\n",
    "#plt.plot(df_b[x], df_b[x]) # uncomment if you want display the bisector\n",
    "#m, b = np.polyfit(df_b[x], df_b[y], 1) # uncomment if you want display the linear fit (watch out - what is x?)\n",
    "#plt.plot(df_b[x], b+m*df_b[x])\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "# correlations\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "corrp, ppvalue = pearsonr(df_b[x], df_b[y])\n",
    "corrs, spvalue = spearmanr(df_b[x], df_b[y])\n",
    "print('Pearson correlation and p-value', corrp)\n",
    "print('Pearson p-value', ppvalue)\n",
    "print()\n",
    "print('Spearman correlation', corrs)\n",
    "print('Spearman p-value', spvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution discrepancies\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "delta = df_b[x]-df_b[y]\n",
    "\n",
    "plt.hist(delta, bins = 30)\n",
    "plt.show()\n",
    "\n",
    "print(delta.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING good_pointing_X=f(bad_pointing_X), on NEW participant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following the \"correction machine\" idea, we predict good_pointing_X using bad_pointing_X on NEW data, only (147 samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosen variables for modeling\n",
    "chosen_variables = [\n",
    "'bad_pointing_coding_within'\n",
    "#'bad_pointing_coding_between'\n",
    "#'bad_pointing_coding_total' \n",
    "]\n",
    "\n",
    "# target\n",
    "target = 'good_pointing_coding_within'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: according to the \"correction machine logic\", we 1) train on NEW data (where both good and bad pointing variables \n",
    "# are defined), and 2) we predict the \"best guess\" for the good_pointing_X variables on ORIGINAL data, \n",
    "# using the only information available, i.e., the bad_pointing_X variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we train only on NEW data\n",
    "df_train = df[df.New_or_Original=='New']\n",
    "df_train = df_train[np.concatenate((chosen_variables, [target]), axis=0)]\n",
    "df_train = df_train.dropna() # there are no NAs anyhow\n",
    "\n",
    "# we test only on Original data\n",
    "df_test = df[df.New_or_Original=='Original']\n",
    "df_test = df_test[np.concatenate((chosen_variables, [target]), axis=0)]\n",
    "df_test = df_test.dropna() # there are no NAs anyhow\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with what are we going to model?\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "X_train = df_train.drop(columns=[target])\n",
    "y_train = df_train[target]\n",
    "\n",
    "# test data\n",
    "X_test = df_test.drop(columns=[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: univariate regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "\n",
    "print('Linear regression coefficient:', reg.coef_)\n",
    "print('Linear regression: intercept:', reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-values: alternative approach. We use statsmodels\n",
    "import statsmodels.api as sm\n",
    "X_train_p = sm.add_constant(X_train)\n",
    "mod = sm.OLS(y_train,X_train_p)\n",
    "\n",
    "fii = mod.fit()\n",
    "print(fii.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PLOT PREDICTIONS VS TRUE VALUES\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_train, y_train, edgecolors=(0, 0, 0))\n",
    "\n",
    "plt.plot(X_train, reg.predict(X_train))\n",
    "ax.set_xlabel('Pred')\n",
    "ax.set_ylabel('True_y')\n",
    "#path_png = 'INSERT PATH.png'\n",
    "#figure.savefig(path_png, dpi=400)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT RESIDUALS\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the residuals after fitting a linear model\n",
    "resid= sns.residplot(x=reg.predict(X_train), y=y_train, lowess=False, label=None, color=\"b\")\n",
    "resid\n",
    "figure = resid.get_figure()\n",
    "#path_png = 'INSERT PATH.png'\n",
    "#figure.savefig(path_png, dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAM RESIDUALS\n",
    "# histogram of test scores\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(y_train-reg.predict(X_train), bins = 30)\n",
    "#hist_png = 'INSERT PATH.png'\n",
    "#plt.savefig(hist_png, dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting best model to whole dataset *IN SAMPLE*\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "print('R^2 on whole dataset')\n",
    "print(r2_score(y_train, reg.predict(X_train)))\n",
    "print('---------------------')\n",
    "print('MSE on whole dataset')\n",
    "print(mean_squared_error(y_train, reg.predict(X_train)))\n",
    "print('---------------------')\n",
    "print('MAE on whole dataset')\n",
    "print(mean_absolute_error(y_train, reg.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness of performance: cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 is in-sample. Does it drop in presence of repeated cross-validation? If yes, can we quantify this drop? We do it\n",
    "# for the univariate regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# scorer\n",
    "###############################################################\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_scorer = make_scorer(r2_score)\n",
    "\n",
    "# choice of scorer\n",
    "scorer = r2_scorer\n",
    "\n",
    "# random state\n",
    "###############################################################\n",
    "random_state=123\n",
    "                            \n",
    "# regressor (univariate linear regression)\n",
    "###############################################################\n",
    "clf = linear_model.LinearRegression()\n",
    "    \n",
    "# GRID SEARCH\n",
    "##############################################################\n",
    "\n",
    "# pipeline\n",
    "pipe = Pipeline([('clf', clf)])\n",
    "\n",
    "# PARAMETER GRID - we do nothing\n",
    "##############################################################\n",
    "param_grid = {}\n",
    "\n",
    "# The repeated k-fold\n",
    "##############################################################\n",
    "n_folds=5     \n",
    "n_repeats=100  \n",
    "\n",
    "skfold = RepeatedKFold(n_splits=n_folds,\n",
    "                       n_repeats=n_repeats,\n",
    "                       random_state=random_state)\n",
    "\n",
    "# GRID SEARCH\n",
    "#############################################################\n",
    "grid_clf = GridSearchCV(pipe, \n",
    "                        param_grid,\n",
    "                        scoring=scorer,\n",
    "                        cv=skfold, \n",
    "                        verbose=5)\n",
    "                        \n",
    "# RUNNING THE GRID\n",
    "############################################\n",
    "grid_clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# COLLECTING RESULTS\n",
    "##############################################################\n",
    "\n",
    "# best estimator\n",
    "clf_b = grid_clf.best_estimator_\n",
    "\n",
    "# print results\n",
    "print('-------------------------------------------------------')\n",
    "print('-------------------------------------------------------')\n",
    "print('Best parameters:', grid_clf.best_params_)\n",
    "print('-------------------------------------------------------')\n",
    "print('-------------------------------------------------------')\n",
    "print('Mean performance (and standard deviation):')\n",
    "print(grid_clf.cv_results_['mean_test_score'][grid_clf.best_index_])\n",
    "print(grid_clf.cv_results_['std_test_score'][grid_clf.best_index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double chek on the model\n",
    "clf_b.fit(X_train, y_train)\n",
    "\n",
    "print('R^2 on whole dataset')\n",
    "print(r2_score(y_train, clf_b.predict(X_train)))\n",
    "print('---------------------')\n",
    "print('MSE on whole dataset')\n",
    "print(mean_squared_error(y_train, clf_b.predict(X_train)))\n",
    "print('---------------------')\n",
    "print('MAE on whole dataset')\n",
    "print(mean_absolute_error(y_train, clf_b.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: easy regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# scorer\n",
    "###############################################################\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "r2_scorer = make_scorer(r2_score)\n",
    "mean_sq_scorer = make_scorer(mean_squared_error, greater_is_better=False) # important: the higher, the worse\n",
    "mean_ab_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# choice of scorer\n",
    "#scorer = mean_sq_scorer\n",
    "scorer = r2_scorer\n",
    "\n",
    "# random state\n",
    "###############################################################\n",
    "random_state=123\n",
    "                            \n",
    "# regressor\n",
    "###############################################################\n",
    "clf = DecisionTreeRegressor(random_state=random_state)\n",
    "    \n",
    "# GRID SEARCH\n",
    "##############################################################\n",
    "\n",
    "# pipeline\n",
    "pipe = Pipeline([('clf', clf)])\n",
    "\n",
    "# PARAMETER GRID\n",
    "##############################################################\n",
    "param_grid = {'clf__max_depth': [1, 2, 3, 4, 5, 6, 7]}\n",
    "\n",
    "# # THE REPEATED K FOLD\n",
    "# #########################################\n",
    "n_folds=5     #5\n",
    "n_repeats=100  #50\n",
    "\n",
    "skfold = RepeatedKFold(n_splits=n_folds,\n",
    "                        n_repeats=n_repeats,\n",
    "                        random_state=random_state)\n",
    "\n",
    "# GRID SEARCH\n",
    "#############################################\n",
    "grid_clf = GridSearchCV(pipe, \n",
    "                        param_grid,\n",
    "                        scoring=scorer,\n",
    "                        cv=skfold, \n",
    "                        verbose=5)\n",
    "                        \n",
    "# RUNNING THE GRID\n",
    "############################################\n",
    "grid_clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLECTING RESULTS\n",
    "##############################################################\n",
    "\n",
    "# best estimator\n",
    "clf_b = grid_clf.best_estimator_\n",
    "\n",
    "# print results\n",
    "print('-------------------------------------------------------')\n",
    "print('-------------------------------------------------------')\n",
    "print('Best parameters:', grid_clf.best_params_)\n",
    "print('-------------------------------------------------------')\n",
    "print('-------------------------------------------------------')\n",
    "print('Mean performance (and standard deviation):')\n",
    "print(grid_clf.cv_results_['mean_test_score'][grid_clf.best_index_])\n",
    "print(grid_clf.cv_results_['std_test_score'][grid_clf.best_index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_b.named_steps['clf'].tree_.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis tree\n",
    "clf = clf_b.named_steps['clf']\n",
    "\n",
    "n_nodes = clf.tree_.node_count\n",
    "children_left = clf.tree_.children_left\n",
    "children_right = clf.tree_.children_right\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "while len(stack) > 0:\n",
    "    # `pop` ensures each node is only visited once\n",
    "    node_id, depth = stack.pop()\n",
    "    node_depth[node_id] = depth\n",
    "\n",
    "    # If the left and right child of a node is not the same we have a split\n",
    "    # node\n",
    "    is_split_node = children_left[node_id] != children_right[node_id]\n",
    "    # If a split node, append left and right children and depth to `stack`\n",
    "    # so we can loop through them\n",
    "    if is_split_node:\n",
    "        stack.append((children_left[node_id], depth + 1))\n",
    "        stack.append((children_right[node_id], depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print(\"The binary tree structure has {n} nodes and has \"\n",
    "      \"the following tree structure:\\n\".format(n=n_nodes))\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        print(\"{space}node={node} is a leaf node.\".format(\n",
    "            space=node_depth[i] * \"\\t\", node=i))\n",
    "    else:\n",
    "        print(\"{space}node={node} is a split node: \"\n",
    "              \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "              \"else to node {right}.\".format(\n",
    "                  space=node_depth[i] * \"\\t\",\n",
    "                  node=i,\n",
    "                  left=children_left[i],\n",
    "                  feature=feature[i],\n",
    "                  threshold=threshold[i],\n",
    "                  right=children_right[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
